{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2173af48",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b324e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from selenium import webdriver\n",
    "import requests\n",
    "import re\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52073bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the driver\n",
    "\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\aisha\\Downloads\\chromedriver_win32 (1)\")\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa39478c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the website on automated chrome browser\n",
    "\n",
    "url='https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos'\n",
    "driver.get(url)\n",
    "time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cfab93",
   "metadata": {},
   "source": [
    "You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdd3446",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrapping details of a table\n",
    "\n",
    "table=driver.find_elements(By.XPATH,'/html/body/div[2]/div/div[3]/main/div[3]/div[3]/div[1]/table[2]')\n",
    "\n",
    "# Read text attribute from each element\n",
    "for elt in table:\n",
    "    print(elt.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4319a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the number of rows in body\n",
    "rows = 1+len(driver.find_elements(By.XPATH,\n",
    "    \"/html/body/div[2]/div/div[3]/main/div[3]/div[3]/div[1]/table[2]\"))\n",
    " \n",
    "# Obtain the number of columns in table\n",
    "cols = len(driver.find_elements(By.XPATH,\n",
    "    \"/html/body/div[2]/div/div[3]/main/div[3]/div[3]/div[1]/table[2]\"))\n",
    " \n",
    "# Print rows and columns\n",
    "print(rows)\n",
    "print(cols)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d3ef3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#finding rank \n",
    "rank=[]\n",
    "\n",
    "ranking = driver.find_elements(By.XPATH,'//td[@align=\"center\"]')\n",
    "for i in ranking:\n",
    "    rank.append(i.text.replace('.', '').replace(' ', ''))\n",
    "    \n",
    "    RANK = []\n",
    "\n",
    "    for i in rank[0:30:3]:\n",
    "        RANK.append(i)\n",
    "        \n",
    "    for i in rank[30: :2]:\n",
    "        RANK.append(i)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cff2783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding Name\n",
    "\n",
    "name=[]\n",
    "\n",
    "name_info = driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]//td')\n",
    "for i in name_info:\n",
    "    name.append(i.text)\n",
    "    print(name) \n",
    "    \n",
    "    NAME = []\n",
    "for i in name[1: :6]:\n",
    "    NAME.append(i.replace('\"', ''))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf555a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having Artist\n",
    "Artist = []\n",
    "\n",
    "artist = driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter']//td\")\n",
    "for i in artist:\n",
    "    Artist.append(i.text)\n",
    "\n",
    "ARTIST = []\n",
    "for i in Artist[2: :6]:\n",
    "    ARTIST.append(i.replace('\"', ''))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9945f51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having Artist\n",
    "Upload_date = []\n",
    "\n",
    "upload = driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter']//td\")\n",
    "\n",
    "for i in upload:\n",
    "    Upload_date.append(i.text)\n",
    "\n",
    "UPLOAD_DATE = []\n",
    "for i in Upload_date[4: :6]:\n",
    "    UPLOAD_DATE.append(i.replace('\"', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75b9f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having Artist\n",
    "\n",
    "view = driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter']//td\")\n",
    "\n",
    "#to remove extra data other than output we required\n",
    "View = [] \n",
    "\n",
    "for i in view:\n",
    "    View.append(i.text)\n",
    "\n",
    "VIEW_billions = []\n",
    "for i in View[3: :6]:\n",
    "    VIEW_billions.append(i.replace('\"', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c263a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Record = pd.DataFrame({})\n",
    "Record['Rank'] = RANK[0:30]\n",
    "Record['Name']=NAME[0:30]\n",
    "Record['Artist'] = ARTIST[0:30]\n",
    "Record['Upload date']=UPLOAD_DATE[0:30]\n",
    "Record['Views']=VIEW_billions[0:30]\n",
    "Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d21476b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef4a30b1",
   "metadata": {},
   "source": [
    "2. Scrape the details team Indiaâ€™s international fixtures from bcci.tv. \n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1stODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245acc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16cd64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the website on automated chrome browser\n",
    "\n",
    "page='https://www.bcci.tv/'\n",
    "driver.get(page)\n",
    "time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212a6261",
   "metadata": {},
   "outputs": [],
   "source": [
    "#serch button click\n",
    "Ficxture_button = driver.find_element(By.XPATH,\"/html/body/nav/div[1]/div[2]/ul[1]/li[2]/a\")\n",
    "Ficxture_button.click()\n",
    "\n",
    "#//div[@class='navigation__drop-down drop-down drop-down--reveal-on-hover']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbded2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#serch button click\n",
    "Ficx_button = driver.find_element(By.XPATH,\"/html/body/div[2]/div[1]/div/ul/li[2]\")\n",
    "Ficx_button.click()\n",
    "\n",
    "#/html/body/div[2]/div[1]/div/ul/li[1]/a\n",
    "#/html/body/div[2]/div[2]/div/div/div/div[2]/div[2]/div/div[3]/div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9f8ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "#main table button click \n",
    "main_table = driver.find_element(By.XPATH,'//div[@class=\"results-tab-inner row\"]')\n",
    "print(main_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736d33b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#serch button click\n",
    "match_button = driver.find_element(By.XPATH,\"/html/body/div[4]/div/div/div[2]/div/div/div[3]/div/div[2]/div/ul/li[3]\")\n",
    "match_button.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7786dce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find detail table \n",
    "\n",
    "match = driver.find_elements(By.XPATH,\"//strong[@class='fixture__name fixture__name--with-margin']\")\n",
    "Match_title = []\n",
    "for i in match:\n",
    "    Match_title.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56f6dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Match title\n",
    "\n",
    "match_1=driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div/div/div/div[2]/div/div[3]/div[1]/div')\n",
    "Match_T = []\n",
    "for i in match:\n",
    "    Match_T.append(i.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a85e75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d0c4c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27e4b20a",
   "metadata": {},
   "source": [
    "3. Scrape the details of State-wise GDP ofIndia fromstatisticstime.com. \n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)- at current prices\n",
    "D) GSDP(19-20)- at current prices\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dd443d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the web driver\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "#Get url in web driver first\n",
    "url = 'http://statisticstimes.com/'\n",
    "driver.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b83b6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#serch button click\n",
    "Economy_b = driver.find_element(By.XPATH,\"/html/body/div[2]/div[1]/div[2]/div[2]\")\n",
    "Economy_b.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3dab3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#serch button click\n",
    "India_B = driver.find_element(By.XPATH,\"/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]\")\n",
    "India_B.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106e5a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#serch button click\n",
    "\n",
    "India_B = driver.find_element(By.XPATH,\"/html/body/div[2]/div[2]/div[2]/ul/li[1]/a\")\n",
    "India_B.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1dac63",
   "metadata": {},
   "source": [
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)- at current prices\n",
    "D) GSDP(19-20)- at current prices\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f657f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having rank\n",
    "rank = driver.find_elements(By.XPATH,\"//td[@class='data1']\")\n",
    "\n",
    "#to remove extra data other than output we required\n",
    "Rank = []\n",
    "for i in rank:\n",
    "    Rank.append(i.text)\n",
    "\n",
    "#extract the tag having state\n",
    "state_of_india = driver.find_elements(By.XPATH,\"//td[@class='name']\")\n",
    "\n",
    "#to remove extra data other than output we required\n",
    "State = []\n",
    "for i in state_of_india:\n",
    "    State.append(i.text)\n",
    "\n",
    "#extract the tag having GSPD_Current\n",
    "current = driver.find_elements(By.XPATH,\"//td[@class='data']\")\n",
    "\n",
    "#to remove extra data other than output we required\n",
    "GSPD_Current = []\n",
    "for i in current:\n",
    "    GSPD_Current.append(i.text)\n",
    "    \n",
    "GDPS_19_20 = []\n",
    "for i in GSPD_Current[0: :5]:\n",
    "    GDPS_19_20.append(i)\n",
    "\n",
    "#extract the tag \n",
    "current_18_19 = driver.find_elements(By.XPATH,\"//td[@class='data sorting_1']\")\n",
    "\n",
    "#to remove extra data other than output we required\n",
    "GSPD_18_19 = []\n",
    "for i in current_18_19:\n",
    "    GSPD_18_19.append(i.text)\n",
    "\n",
    "# extracg the data of share\n",
    "Share_19_20 = []\n",
    "for i in GSPD_Current[1: :5]:\n",
    "    Share_19_20.append(i)\n",
    "\n",
    "# extracg the data of GDP in Billions\n",
    "GDP = []\n",
    "for i in GSPD_Current[2: :5]:\n",
    "    GDP.append(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ce37c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stats = pd.DataFrame({})\n",
    "Stats['Rank'] = RANK[0:33]\n",
    "Stats['STATE']= State[0:33]\n",
    "Stats['GSDP (18-19)'] = GDPS_19_20[0:33]\n",
    "Stats['GSDP (18-19)'] = GSPD_18_19[0:33] \n",
    "Stats['SHARE (19-20)'] = Share_19_20[0:33]\n",
    "Stats['GDP'] = GDP[0:33] \n",
    "Stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cff0d8",
   "metadata": {},
   "source": [
    "4. Scrape the details of trending repositories on Github.com. \n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1131a5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the web driver\n",
    "web_driver = webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "\n",
    "#Get url in web driver first\n",
    "url = 'https://github.com/'\n",
    "web_driver.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d208409",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspect button to click on open source\n",
    "\n",
    "button_open_source= web_driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/button')\n",
    "\n",
    "button_open_source.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea67945",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspect for Skill,Designations,Companies field\n",
    "\n",
    "repo_search = web_driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/div[3]/ul/li[2]/a\")\n",
    "\n",
    "repo_search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcb6439",
   "metadata": {},
   "outputs": [],
   "source": [
    "table2=web_driver.find_elements(By.XPATH,'/html/body/div[1]/div[4]/main/div[3]/div/div[2]')\n",
    "\n",
    "for elt in table2:\n",
    "    print(elt.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09bacbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having rank\n",
    "#A) Repository title B) Repository description C) Contributors count D) Language used Note\n",
    "\n",
    "repo_title = web_driver.find_elements(By.XPATH,\"//h2[@class='h3 lh-condensed']\")\n",
    "#to remove extra data other than output we required\n",
    "\n",
    "Repository_title = []\n",
    "for i in repo_title:\n",
    "    Repository_title.append(i.text)\n",
    "Repository_title\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48343c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Repository description\n",
    "\n",
    "repo_desc= web_driver.find_elements(By.XPATH,\"//p[@class='col-9 color-fg-muted my-1 pr-4']\")\n",
    "\n",
    "Repository_desc = []\n",
    "for i in repo_desc:\n",
    "    Repository_desc.append(i.text)\n",
    "Repository_desc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a17249",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Contritbutors count\n",
    "\n",
    "contr_count= web_driver.find_elements(By.XPATH,\"//span[@class='d-inline-block mr-3']\")\n",
    "\n",
    "Contri_count = []\n",
    "for i in contr_count:\n",
    "    Contri_count.append(i.text)\n",
    "Contri_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b0a097",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Language used Note\n",
    "\n",
    "lang= web_driver.find_elements(By.XPATH,\"//span[@itemprop='programmingLanguage']\")\n",
    "\n",
    "lang_note = []\n",
    "for i in lang:\n",
    "    lang_note.append(i.text)\n",
    "lang_note\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1348e4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Git = pd.DataFrame({})\n",
    "Git['Repository_Title'] = pd.Series([Repository_title])\n",
    "Git['Repository_Desc']= pd.Series([Repository_desc])\n",
    "Git['Contributor_count'] = pd.Series([Contri_count])\n",
    "Git['Language'] = pd.Series([lang_note])\n",
    "Git\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1853cc",
   "metadata": {},
   "source": [
    "5. Scrape the details of top 100 songs on billiboard.com. \n",
    "Url = https:/www.billboard.com/\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7aa091",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the web driver\n",
    "web_driver = webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "#Get url in web driver first\n",
    "url = 'https://www.billboard.com/'\n",
    "web_driver.get(url)\n",
    "#the url will open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4600defc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#serch button click\n",
    "charts_button = web_driver.find_element(By.XPATH,\"//div[@class='search-form']\")\n",
    "charts_button.click()\n",
    "\n",
    "\n",
    "#/html/body/div[5]/div[9]/div/div/div/ul/li[1]/h3/button/span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9926e6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#serch button click\n",
    "top100_button = web_driver.find_element(By.XPATH,\"/html/body/div[4]/div[9]/div/div/div/ul/li[1]/ul/li[2]\")\n",
    "top100_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14e5851",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having song name\n",
    "name = web_driver.find_element(By.XPATH,\"//span[@class='chart-element__information__song text--truncate color--primary']\")\n",
    "#to remove extra data other than output we required\n",
    "Song_name = []\n",
    "for i in name:\n",
    "    Song_name.append(i.text)\n",
    "\n",
    "#extract the tag having artist name\n",
    "Artist = web_driver.find_element(By.XPATH,\"//span[@class='chart-element__information__artist text--truncate color--secondary']\")\n",
    "#to remove extra data other than output we required\n",
    "Artist_name = []\n",
    "for i in Artist:\n",
    "    Artist_name.append(i.text)\n",
    "\n",
    "#extract the tag having last week rank\n",
    "last_rank = web_driver.find_element(By.XPATH,\"//div[@class='chart-element__meta text--center color--secondary text--last']\")\n",
    "#to remove extra data other than output we required\n",
    "Last_week_rank = []\n",
    "for i in last_rank:\n",
    "    Last_week_rank.append(i.text)\n",
    "\n",
    "#extract the tag having last peak rank\n",
    "peak_rank = web_driver.find_element(By.XPATH,\"//div[@class='chart-element__meta text--center color--secondary text--peak']\")\n",
    "Peak_rank = []\n",
    "for i in peak_rank:\n",
    "    Peak_rank.append(i.text)\n",
    "\n",
    "#extract the tag having last week rank\n",
    "woc = web_driver.find_element(By.XPATH,\"//div[@class='chart-element__meta text--center color--secondary text--week']\")\n",
    "Weeks_on_chart = []\n",
    "for i in woc:\n",
    "    Weeks_on_chart.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497ba2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make data frame of hot 100 from https://www.billboard.com/\n",
    "HTop_list_100 = pd.DataFrame({})\n",
    "HTop_list_100['Song_name']= Song_name\n",
    "HTop_list_100['Artist_name'] = Artist_name\n",
    "HTop_list_100['Last_week_rank'] = Last_week_rank \n",
    "HTop_list_100['Peak_rank'] = Peak_rank\n",
    "HTop_list_100['Weeks_on_Board'] = Weeks_on_chart \n",
    "HTop_list_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e92674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087a584d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5cf49b7f",
   "metadata": {},
   "source": [
    "6. Scrape the details of Highest sellingnovels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey\u0002compare\n",
    "You have to find the following details:\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea973e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the web driver\n",
    "web_driver = webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "#Get url in web driver first\n",
    "url = 'https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/'\n",
    "web_driver.get(url)\n",
    "#the url will open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8db5bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having rank\n",
    "rank = web_driver.find_elements(By.XPATH,\"//td[@class='left']\")\n",
    "#to remove extra data other than output we required\n",
    "\n",
    "Book_Name = []\n",
    "for i in rank:\n",
    "    Book_Name.append(i.text)\n",
    "BOOK_NAME = []\n",
    "for i in Book_Name[1: :5]:\n",
    "    BOOK_NAME.append(i)\n",
    "\n",
    "Auther_Name = []\n",
    "for i in Rank[2: :5]:\n",
    "    Auther_Name.append(i)\n",
    "\n",
    "Volume_sold = []\n",
    "for i in Rank[3: :5]:\n",
    "    Volume_sold.append(i)\n",
    "\n",
    "Publisher = []\n",
    "for i in Rank[4: :5]:\n",
    "    Publisher.append(i)\n",
    "\n",
    "#extract the tag having rank\n",
    "genre = web_driver.find_elements(By.XPATH,\"//td[@class='last left']\")\n",
    "#to remove extra data other than output we required\n",
    "Genre = []\n",
    "for i in genre:\n",
    "    Genre.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca98a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make data frame of hot 100 from https://www.billboard.com/\n",
    "Novels = pd.DataFrame({})\n",
    "Novels['BOOK_NAME']= BOOK_NAME\n",
    "Novels['Auther_Name'] = Auther_Name\n",
    "Novels['Volume_sold'] = Volume_sold \n",
    "Novels['Publisher'] = Publisher\n",
    "Novels['Genre'] = Genre \n",
    "Novels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2f4071",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "382c805b",
   "metadata": {},
   "source": [
    "7. Scrape the details most watched tv series of all time from imdb.com. \n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a6c163",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the web driver\n",
    "web_driver = webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "#Get url in web driver first\n",
    "url = 'https://www.imdb.com/list/ls095964455/'\n",
    "web_driver.get(url)\n",
    "#the url will open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e45c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having Name\n",
    "name = web_driver.find_elements(By.XPATH,\"//h3[@class='lister-item-header']//a\")\n",
    "#to remove extra data other than output we required\n",
    "Name=[]\n",
    "for i in name:\n",
    "    Name.append(i.text)\n",
    "\n",
    "#extract the tag having year span\n",
    "year = web_driver.find_elements(By.XPATH,\"//span[@class='lister-item-year text-muted unbold']\")\n",
    "#to remove extra data other than output we required\n",
    "Year_Span=[]\n",
    "for i in year:\n",
    "    Year_Span.append(i.text)\n",
    "\n",
    "#extract the tag having Genre\n",
    "genre = web_driver.find_elements(By.XPATH,\"//span[@class='genre']\")\n",
    "#to remove extra data other than output we required\n",
    "Genre=[]\n",
    "for i in genre:\n",
    "    Genre.append(i.text)\n",
    "\n",
    "#extract the tag having run time\n",
    "run = web_driver.find_elements(By.XPATH,\"//span[@class='runtime']\")\n",
    "#to remove extra data other than output we required\n",
    "Run_Time=[]\n",
    "for i in run:\n",
    "    Run_Time.append(i.text)\n",
    "\n",
    "#extract the tag having ratings\n",
    "ratings = web_driver.find_elements(By.XPATH,\"//div[@class='ipl-rating-star small']\")\n",
    "#to remove extra data other than output we required\n",
    "Ratings=[]\n",
    "for i in ratings:\n",
    "    Ratings.append(i.text)\n",
    "\n",
    "#extract the tag having voting\n",
    "voting = web_driver.find_elements(By.XPATH,\"//span[@name='nv']\")\n",
    "\n",
    "#to remove extra data other than output we required\n",
    "Voting=[]\n",
    "for i in voting:\n",
    "    Voting.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dcf402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make data frame of tv series 100 from imdb.com\n",
    "TELEVISION_S = pd.DataFrame({})\n",
    "TELEVISION_S['NAME']= Name\n",
    "TELEVISION_S['Year Span'] = Year_Span\n",
    "TELEVISION_S['Genre'] = Genre \n",
    "TELEVISION_S['Run Time'] = Run_Time\n",
    "TELEVISION_S['Ratings'] = Ratings \n",
    "TELEVISION_S['Voting'] = Voting \n",
    "TELEVISION_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373bacc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c93a73b",
   "metadata": {},
   "source": [
    "8. Details of Datasetsfrom UCI machine learning repositories. \n",
    "Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute\n",
    "G) Year\n",
    "Note: - from the home page you have to go to the ShowAllDataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f73c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the web driver\n",
    "web_driver = webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "#Get url in web driver first\n",
    "url = 'https://archive.ics.uci.edu/'\n",
    "web_driver.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8edb3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#serch button click\n",
    "dataset_button = web_driver.find_element(By.XPATH,\"/html/body/table[1]/tbody/tr/td[2]/span[2]/a\")\n",
    "dataset_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcc7be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having dataset Name\n",
    "name = web_driver.find_elements(By.XPATH,\"//td[@valign='top']//a\")\n",
    "\n",
    "\n",
    "#to remove extra data other than output we required\n",
    "\n",
    "Dataset_Name=[]\n",
    "for i in name:\n",
    "    Dataset_Name.append(i.text)\n",
    "Dataset_name = []\n",
    "for i in Dataset_Name[44: :2]:\n",
    "    Dataset_name.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae6616e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having dataset Name\n",
    "datat = web_driver.find_elements(By.XPATH,\"//td[@valign='top']//p\")\n",
    "#to remove extra data other than output we required\n",
    "Data_type=[]\n",
    "for i in datat:\n",
    "    Data_type.append(i.text)\n",
    "\n",
    "Data_Type=[]\n",
    "for i in Data_type[25: :7]:\n",
    "    Data_Type.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1821e36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having dataset Name\n",
    "task = web_driver.find_elements(By.XPATH,\"//td[@valign='top']//p\")\n",
    "#to remove extra data other than output we required\n",
    "Task=[]\n",
    "for i in task:\n",
    "    Task.append(i.text)\n",
    "\n",
    "TASK=[]\n",
    "for i in Task[26: :7]:\n",
    "    TASK.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62eb3196",
   "metadata": {},
   "outputs": [],
   "source": [
    "Attribute_Type=[]\n",
    "for i in Data_type[27: :7]:\n",
    "    Attribute_Type.append(i)\n",
    "Instances = []\n",
    "for i in Data_type[28: :7]:\n",
    "    Instances.append(i)\n",
    "Attribute=[]\n",
    "for i in Data_type[29: :7]:\n",
    "    Attribute.append(i)\n",
    "Year=[]\n",
    "for i in Data_type[30: :7]:\n",
    "    Year.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284ee28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make data frame of Datasets from UCI machine learning repositories from Url = https://archive.ics.uci.edu/\n",
    "\n",
    "MACHINE_LEARNING_REPO = pd.DataFrame({})\n",
    "MACHINE_LEARNING_REPO['Dataset_name']= Dataset_name\n",
    "MACHINE_LEARNING_REPO['Data_Type'] = Data_Type\n",
    "MACHINE_LEARNING_REPO['Task'] = TASK \n",
    "MACHINE_LEARNING_REPO['Attribute_Type'] = Attribute_Type\n",
    "MACHINE_LEARNING_REPO['Instances'] = Instances \n",
    "MACHINE_LEARNING_REPO['Attribute'] = Attribute \n",
    "MACHINE_LEARNING_REPO['Year'] = Year\n",
    "MACHINE_LEARNING_REPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6fb29a",
   "metadata": {},
   "source": [
    "9. Scrape the details of Data science recruiters Url = https://www.naukri.com/hr-recruiters-consultants\n",
    "You have to find the following details: \n",
    "A) Name\n",
    "B) Designation\n",
    "C)Company \n",
    "D)Skills they hire for \n",
    "E) Location\n",
    "Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and \n",
    "click on search. All this should be done through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "ba45a3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the web driver\n",
    "web_driver = webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "#Get url in web driver first\n",
    "url = ' https://www.naukri.com/hr-recruiters-consultants'\n",
    "web_driver.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "4c596204",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#inspect for Skill,Designations,Companies field\n",
    "ds_search = web_driver.find_element(By.XPATH,\"//input[@class='sugInp']\")\n",
    "\n",
    "#this will write text on search bar\n",
    "ds_search.send_keys('Data science')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "880cc8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#serch button click\n",
    "search_button = web_driver.find_element(By.XPATH,\"//button[@class='fl qsbSrch blueBtn']\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6638e56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccddbaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1647ac3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d49adfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

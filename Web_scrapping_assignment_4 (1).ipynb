{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2173af48",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b324e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from selenium import webdriver\n",
    "import requests\n",
    "import re\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52073bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets first connect to the driver\n",
    "\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\aisha\\Downloads\\chromedriver_win32 (1)\")\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa39478c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the website on automated chrome browser\n",
    "\n",
    "url='https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos'\n",
    "driver.get(url)\n",
    "time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cfab93",
   "metadata": {},
   "source": [
    "You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdd3446",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrapping details of a table\n",
    "\n",
    "table=driver.find_elements(By.XPATH,'/html/body/div[2]/div/div[3]/main/div[3]/div[3]/div[1]/table[2]')\n",
    "\n",
    "# Read text attribute from each element\n",
    "for elt in table:\n",
    "    print(elt.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4319a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the number of rows in body\n",
    "rows = 1+len(driver.find_elements(By.XPATH,\n",
    "    \"/html/body/div[2]/div/div[3]/main/div[3]/div[3]/div[1]/table[2]\"))\n",
    " \n",
    "# Obtain the number of columns in table\n",
    "cols = len(driver.find_elements(By.XPATH,\n",
    "    \"/html/body/div[2]/div/div[3]/main/div[3]/div[3]/div[1]/table[2]\"))\n",
    " \n",
    "# Print rows and columns\n",
    "print(rows)\n",
    "print(cols)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d3ef3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#finding rank \n",
    "rank=[]\n",
    "\n",
    "ranking = driver.find_elements(By.XPATH,'//td[@align=\"center\"]')\n",
    "for i in ranking:\n",
    "    rank.append(i.text.replace('.', '').replace(' ', ''))\n",
    "    \n",
    "    RANK = []\n",
    "\n",
    "    for i in rank[0:30:3]:\n",
    "        RANK.append(i)\n",
    "        \n",
    "    for i in rank[30: :2]:\n",
    "        RANK.append(i)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cff2783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding Name\n",
    "\n",
    "name=[]\n",
    "\n",
    "name_info = driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]//td')\n",
    "for i in name_info:\n",
    "    name.append(i.text)\n",
    "    print(name) \n",
    "    \n",
    "    NAME = []\n",
    "for i in name[1: :6]:\n",
    "    NAME.append(i.replace('\"', ''))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf555a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having Artist\n",
    "Artist = []\n",
    "\n",
    "artist = driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter']//td\")\n",
    "for i in artist:\n",
    "    Artist.append(i.text)\n",
    "\n",
    "ARTIST = []\n",
    "for i in Artist[2: :6]:\n",
    "    ARTIST.append(i.replace('\"', ''))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9945f51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having Artist\n",
    "Upload_date = []\n",
    "\n",
    "upload = driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter']//td\")\n",
    "\n",
    "for i in upload:\n",
    "    Upload_date.append(i.text)\n",
    "\n",
    "UPLOAD_DATE = []\n",
    "for i in Upload_date[4: :6]:\n",
    "    UPLOAD_DATE.append(i.replace('\"', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75b9f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having Artist\n",
    "\n",
    "view = driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter']//td\")\n",
    "\n",
    "#to remove extra data other than output we required\n",
    "View = [] \n",
    "\n",
    "for i in view:\n",
    "    View.append(i.text)\n",
    "\n",
    "VIEW_billions = []\n",
    "for i in View[3: :6]:\n",
    "    VIEW_billions.append(i.replace('\"', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "a5c263a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Baby Shark Dance[4]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>12.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Despacito[7]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Johny Johny Yes Papa[14]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>620</td>\n",
       "      <td>Bath Song[15]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>6.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[C]</td>\n",
       "      <td>Shape of You[16]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[D]</td>\n",
       "      <td>See You Again[19]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>Phonics Song with Two Words[24]</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>492</td>\n",
       "      <td>Wheels on the Bus[25]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>5.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11</td>\n",
       "      <td>Uptown Funk[26]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12</td>\n",
       "      <td>Learning Colors – Colorful Eggs on a Farm[27]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>435</td>\n",
       "      <td>Gangnam Style[28]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>391</td>\n",
       "      <td>Masha and the Bear – Recipe for Disaster[33]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>387</td>\n",
       "      <td>Dame Tu Cosita[34]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>380</td>\n",
       "      <td>Axel F[35]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>3.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>379</td>\n",
       "      <td>Sugar[36]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>366</td>\n",
       "      <td>Roar[37]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>364</td>\n",
       "      <td>Counting Stars[38]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>360</td>\n",
       "      <td>Sorry[39]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>359</td>\n",
       "      <td>Baa Baa Black Sheep[40]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>352</td>\n",
       "      <td>Thinking Out Loud[41]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>348</td>\n",
       "      <td>Waka Waka (This Time for Africa)[42]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>345</td>\n",
       "      <td>Dark Horse[43]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>345</td>\n",
       "      <td>Lakdi Ki Kathi[44]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>June 14, 2018</td>\n",
       "      <td>3.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>344</td>\n",
       "      <td>Faded[45]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>342</td>\n",
       "      <td>Perfect[46]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>341</td>\n",
       "      <td>Let Her Go[47]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>338</td>\n",
       "      <td>Girls Like You[48]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>338</td>\n",
       "      <td>Humpty the train on a fruits ride[49]</td>\n",
       "      <td>Kiddiestv Hindi – Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td></td>\n",
       "      <td>Lean On[50]</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[B]</td>\n",
       "      <td>Bailando[51]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                           Name  \\\n",
       "0     1                            Baby Shark Dance[4]   \n",
       "1     2                                   Despacito[7]   \n",
       "2     3                       Johny Johny Yes Papa[14]   \n",
       "3   620                                  Bath Song[15]   \n",
       "4   [C]                               Shape of You[16]   \n",
       "5   [D]                              See You Again[19]   \n",
       "6     8                Phonics Song with Two Words[24]   \n",
       "7   492                          Wheels on the Bus[25]   \n",
       "8    11                                Uptown Funk[26]   \n",
       "9    12  Learning Colors – Colorful Eggs on a Farm[27]   \n",
       "10  435                              Gangnam Style[28]   \n",
       "11  391   Masha and the Bear – Recipe for Disaster[33]   \n",
       "12  387                             Dame Tu Cosita[34]   \n",
       "13  380                                     Axel F[35]   \n",
       "14  379                                      Sugar[36]   \n",
       "15  366                                       Roar[37]   \n",
       "16  364                             Counting Stars[38]   \n",
       "17  360                                      Sorry[39]   \n",
       "18  359                        Baa Baa Black Sheep[40]   \n",
       "19  352                          Thinking Out Loud[41]   \n",
       "20  348           Waka Waka (This Time for Africa)[42]   \n",
       "21  345                                 Dark Horse[43]   \n",
       "22  345                             Lakdi Ki Kathi[44]   \n",
       "23  344                                      Faded[45]   \n",
       "24  342                                    Perfect[46]   \n",
       "25  341                                 Let Her Go[47]   \n",
       "26  338                             Girls Like You[48]   \n",
       "27  338          Humpty the train on a fruits ride[49]   \n",
       "28                                         Lean On[50]   \n",
       "29  [B]                                   Bailando[51]   \n",
       "\n",
       "                                           Artist        Upload date  Views  \n",
       "0     Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016  12.85  \n",
       "1                                      Luis Fonsi   January 12, 2017   8.16  \n",
       "2                                     LooLoo Kids    October 8, 2016   6.70  \n",
       "3                      Cocomelon – Nursery Rhymes        May 2, 2018   6.20  \n",
       "4                                      Ed Sheeran   January 30, 2017   6.00  \n",
       "5                                     Wiz Khalifa      April 6, 2015   5.89  \n",
       "6                                       ChuChu TV      March 6, 2014   5.30  \n",
       "7                      Cocomelon – Nursery Rhymes       May 24, 2018   5.24  \n",
       "8                                     Mark Ronson  November 19, 2014   4.92  \n",
       "9                                     Miroshka TV  February 27, 2018   4.89  \n",
       "10                                            Psy      July 15, 2012   4.80  \n",
       "11                                     Get Movies   January 31, 2012   4.55  \n",
       "12                                      El Chombo      April 5, 2018   4.35  \n",
       "13                                     Crazy Frog      June 16, 2009   3.91  \n",
       "14                                       Maroon 5   January 14, 2015   3.87  \n",
       "15                                     Katy Perry  September 5, 2013   3.80  \n",
       "16                                    OneRepublic       May 31, 2013   3.79  \n",
       "17                                  Justin Bieber   October 22, 2015   3.66  \n",
       "18                     Cocomelon – Nursery Rhymes      June 25, 2018   3.64  \n",
       "19                                     Ed Sheeran    October 7, 2014   3.60  \n",
       "20                                        Shakira       June 4, 2010   3.59  \n",
       "21                                     Katy Perry  February 20, 2014   3.52  \n",
       "22                                   Jingle Toons      June 14, 2018   3.48  \n",
       "23                                    Alan Walker   December 3, 2015   3.45  \n",
       "24                                     Ed Sheeran   November 9, 2017   3.45  \n",
       "25                                      Passenger      July 25, 2012   3.44  \n",
       "26                                       Maroon 5       May 31, 2018   3.42  \n",
       "27  Kiddiestv Hindi – Nursery Rhymes & Kids Songs   January 26, 2018   3.41  \n",
       "28                                    Major Lazer     March 22, 2015   3.38  \n",
       "29                               Enrique Iglesias     April 11, 2014   3.38  "
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Record = pd.DataFrame({})\n",
    "Record['Rank'] = RANK[0:30]\n",
    "Record['Name']=NAME[0:30]\n",
    "Record['Artist'] = ARTIST[0:30]\n",
    "Record['Upload date']=UPLOAD_DATE[0:30]\n",
    "Record['Views']=VIEW_billions[0:30]\n",
    "Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d21476b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7723b16d",
   "metadata": {},
   "source": [
    "2. Scrape the details team India’s international fixtures from bcci.tv. \n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1stODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245acc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16cd64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the website on automated chrome browser\n",
    "\n",
    "page='https://www.bcci.tv/'\n",
    "driver.get(page)\n",
    "time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b325cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#serch button click\n",
    "Ficxture_button = driver.find_element(By.XPATH,\"/html/body/nav/div[1]/div[2]/ul[1]/li[2]/a\")\n",
    "Ficxture_button.click()\n",
    "\n",
    "#//div[@class='navigation__drop-down drop-down drop-down--reveal-on-hover']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e302a855",
   "metadata": {},
   "outputs": [],
   "source": [
    "#serch button click\n",
    "Ficx_button = driver.find_element(By.XPATH,\"/html/body/div[2]/div[1]/div/ul/li[2]\")\n",
    "Ficx_button.click()\n",
    "\n",
    "#/html/body/div[2]/div[1]/div/ul/li[1]/a\n",
    "#/html/body/div[2]/div[2]/div/div/div/div[2]/div[2]/div/div[3]/div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d2d74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#main table button click \n",
    "main_table = driver.find_element(By.XPATH,'//div[@class=\"results-tab-inner row\"]')\n",
    "print(main_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dee03a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#serch button click\n",
    "match_button = driver.find_element(By.XPATH,\"/html/body/div[4]/div/div/div[2]/div/div/div[3]/div/div[2]/div/ul/li[3]\")\n",
    "match_button.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7786dce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find detail table \n",
    "\n",
    "match = driver.find_elements(By.XPATH,\"//strong[@class='fixture__name fixture__name--with-margin']\")\n",
    "Match_title = []\n",
    "for i in match:\n",
    "    Match_title.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56f6dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Match title\n",
    "\n",
    "match_1=driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div/div/div/div[2]/div/div[3]/div[1]/div')\n",
    "Match_T = []\n",
    "for i in match:\n",
    "    Match_T.append(i.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8833c5d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9936ea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27e4b20a",
   "metadata": {},
   "source": [
    "3. Scrape the details of State-wise GDP ofIndia fromstatisticstime.com. \n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)- at current prices\n",
    "D) GSDP(19-20)- at current prices\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c27e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the web driver\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "#Get url in web driver first\n",
    "url = 'http://statisticstimes.com/'\n",
    "driver.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1550a279",
   "metadata": {},
   "outputs": [],
   "source": [
    "#serch button click\n",
    "Economy_b = driver.find_element(By.XPATH,\"/html/body/div[2]/div[1]/div[2]/div[2]\")\n",
    "Economy_b.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a62baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#serch button click\n",
    "India_B = driver.find_element(By.XPATH,\"/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]\")\n",
    "India_B.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01eb8aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#serch button click\n",
    "\n",
    "India_B = driver.find_element(By.XPATH,\"/html/body/div[2]/div[2]/div[2]/ul/li[1]/a\")\n",
    "India_B.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38c6d27",
   "metadata": {},
   "source": [
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)- at current prices\n",
    "D) GSDP(19-20)- at current prices\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359b34b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having rank\n",
    "rank = driver.find_elements(By.XPATH,\"//td[@class='data1']\")\n",
    "\n",
    "#to remove extra data other than output we required\n",
    "Rank = []\n",
    "for i in rank:\n",
    "    Rank.append(i.text)\n",
    "\n",
    "#extract the tag having state\n",
    "state_of_india = driver.find_elements(By.XPATH,\"//td[@class='name']\")\n",
    "\n",
    "#to remove extra data other than output we required\n",
    "State = []\n",
    "for i in state_of_india:\n",
    "    State.append(i.text)\n",
    "\n",
    "#extract the tag having GSPD_Current\n",
    "current = driver.find_elements(By.XPATH,\"//td[@class='data']\")\n",
    "\n",
    "#to remove extra data other than output we required\n",
    "GSPD_Current = []\n",
    "for i in current:\n",
    "    GSPD_Current.append(i.text)\n",
    "    \n",
    "GDPS_19_20 = []\n",
    "for i in GSPD_Current[0: :5]:\n",
    "    GDPS_19_20.append(i)\n",
    "\n",
    "#extract the tag \n",
    "current_18_19 = driver.find_elements(By.XPATH,\"//td[@class='data sorting_1']\")\n",
    "\n",
    "#to remove extra data other than output we required\n",
    "GSPD_18_19 = []\n",
    "for i in current_18_19:\n",
    "    GSPD_18_19.append(i.text)\n",
    "\n",
    "# extracg the data of share\n",
    "Share_19_20 = []\n",
    "for i in GSPD_Current[1: :5]:\n",
    "    Share_19_20.append(i)\n",
    "\n",
    "# extracg the data of GDP in Billions\n",
    "GDP = []\n",
    "for i in GSPD_Current[2: :5]:\n",
    "    GDP.append(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "83bc8187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>STATE</th>\n",
       "      <th>GSDP (18-19)</th>\n",
       "      <th>SHARE (19-20)</th>\n",
       "      <th>GDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>620</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[C]</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[D]</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>942,586</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>492</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>862,957</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>861,031</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>809,592</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>435</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>781,653</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>391</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>774,870</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>387</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>734,163</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>380</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>530,363</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>379</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>526,376</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>366</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>487,805</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>364</td>\n",
       "      <td>Assam</td>\n",
       "      <td>315,881</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>360</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>304,063</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>359</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>297,204</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>352</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>245,895</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>348</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>155,956</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>345</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>153,845</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>345</td>\n",
       "      <td>Goa</td>\n",
       "      <td>73,170</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>344</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>49,845</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>342</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>42,114</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>341</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>34,433</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>338</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>33,481</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>338</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>28,723</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td></td>\n",
       "      <td>Manipur</td>\n",
       "      <td>27,870</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[B]</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>27,283</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>134</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>24,603</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[E]</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>22,287</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[65]</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank                      STATE GSDP (18-19) SHARE (19-20)      GDP\n",
       "0      1                Maharashtra    2,632,792        13.94%  399.921\n",
       "1      2                 Tamil Nadu    1,630,208         8.63%  247.629\n",
       "2      3              Uttar Pradesh    1,584,764         8.39%  240.726\n",
       "3    620                    Gujarat    1,502,899         7.96%  228.290\n",
       "4    [C]                  Karnataka    1,493,127         7.91%  226.806\n",
       "5    [D]                West Bengal    1,089,898         5.77%  165.556\n",
       "6      8                  Rajasthan      942,586         4.99%  143.179\n",
       "7    492             Andhra Pradesh      862,957         4.57%  131.083\n",
       "8     11                  Telangana      861,031         4.56%  130.791\n",
       "9     12             Madhya Pradesh      809,592         4.29%  122.977\n",
       "10   435                     Kerala      781,653         4.14%  118.733\n",
       "11   391                      Delhi      774,870         4.10%  117.703\n",
       "12   387                    Haryana      734,163         3.89%  111.519\n",
       "13   380                      Bihar      530,363         2.81%   80.562\n",
       "14   379                     Punjab      526,376         2.79%   79.957\n",
       "15   366                     Odisha      487,805         2.58%   74.098\n",
       "16   364                      Assam      315,881         1.67%   47.982\n",
       "17   360               Chhattisgarh      304,063         1.61%   46.187\n",
       "18   359                  Jharkhand      297,204         1.57%   45.145\n",
       "19   352                Uttarakhand      245,895         1.30%   37.351\n",
       "20   348            Jammu & Kashmir      155,956         0.83%   23.690\n",
       "21   345           Himachal Pradesh      153,845         0.81%   23.369\n",
       "22   345                        Goa       73,170         0.39%   11.115\n",
       "23   344                    Tripura       49,845         0.26%    7.571\n",
       "24   342                 Chandigarh       42,114         0.22%    6.397\n",
       "25   341                 Puducherry       34,433         0.18%    5.230\n",
       "26   338                  Meghalaya       33,481         0.18%    5.086\n",
       "27   338                     Sikkim       28,723         0.15%    4.363\n",
       "28                          Manipur       27,870         0.15%    4.233\n",
       "29   [B]                   Nagaland       27,283         0.14%    4.144\n",
       "30   134          Arunachal Pradesh       24,603         0.13%    3.737\n",
       "31   [E]                    Mizoram       22,287         0.12%    3.385\n",
       "32  [65]  Andaman & Nicobar Islands            -             -        -"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Stats = pd.DataFrame({})\n",
    "Stats['Rank'] = RANK[0:33]\n",
    "Stats['STATE']= State[0:33]\n",
    "Stats['GSDP (18-19)'] = GDPS_19_20[0:33]\n",
    "Stats['GSDP (18-19)'] = GSPD_18_19[0:33] \n",
    "Stats['SHARE (19-20)'] = Share_19_20[0:33]\n",
    "Stats['GDP'] = GDP[0:33] \n",
    "Stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cff0d8",
   "metadata": {},
   "source": [
    "4. Scrape the details of trending repositories on Github.com. \n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656c6857",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the web driver\n",
    "web_driver = webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "\n",
    "#Get url in web driver first\n",
    "url = 'https://github.com/'\n",
    "web_driver.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf85c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspect button to click on open source\n",
    "\n",
    "button_open_source= web_driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/button')\n",
    "\n",
    "button_open_source.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bad0b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspect for Skill,Designations,Companies field\n",
    "\n",
    "repo_search = web_driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/div[3]/ul/li[2]/a\")\n",
    "\n",
    "repo_search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c16d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "table2=web_driver.find_elements(By.XPATH,'/html/body/div[1]/div[4]/main/div[3]/div/div[2]')\n",
    "\n",
    "for elt in table2:\n",
    "    print(elt.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405f4f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having rank\n",
    "#A) Repository title B) Repository description C) Contributors count D) Language used Note\n",
    "\n",
    "repo_title = web_driver.find_elements(By.XPATH,\"//h2[@class='h3 lh-condensed']\")\n",
    "#to remove extra data other than output we required\n",
    "\n",
    "Repository_title = []\n",
    "for i in repo_title:\n",
    "    Repository_title.append(i.text)\n",
    "Repository_title\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548afe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Repository description\n",
    "\n",
    "repo_desc= web_driver.find_elements(By.XPATH,\"//p[@class='col-9 color-fg-muted my-1 pr-4']\")\n",
    "\n",
    "Repository_desc = []\n",
    "for i in repo_desc:\n",
    "    Repository_desc.append(i.text)\n",
    "Repository_desc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2808c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Contritbutors count\n",
    "\n",
    "contr_count= web_driver.find_elements(By.XPATH,\"//span[@class='d-inline-block mr-3']\")\n",
    "\n",
    "Contri_count = []\n",
    "for i in contr_count:\n",
    "    Contri_count.append(i.text)\n",
    "Contri_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6d767c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Language used Note\n",
    "\n",
    "lang= web_driver.find_elements(By.XPATH,\"//span[@itemprop='programmingLanguage']\")\n",
    "\n",
    "lang_note = []\n",
    "for i in lang:\n",
    "    lang_note.append(i.text)\n",
    "lang_note\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "00c6f7ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (24) does not match length of index (25)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22624\\258125205.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mGit\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Repository_Desc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mRepository_desc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m33\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mGit\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Contributor_count'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mContri_count\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m33\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mGit\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Language'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlang_note\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m33\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mGit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m33\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3653\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3654\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3655\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3657\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3830\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3831\u001b[0m         \"\"\"\n\u001b[1;32m-> 3832\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3833\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3834\u001b[0m         if (\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4537\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4538\u001b[1;33m             \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4539\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\common.py\u001b[0m in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    555\u001b[0m     \"\"\"\n\u001b[0;32m    556\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    558\u001b[0m             \u001b[1;34m\"Length of values \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m             \u001b[1;34mf\"({len(data)}) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (24) does not match length of index (25)"
     ]
    }
   ],
   "source": [
    "Git = pd.DataFrame({})\n",
    "Git['Repository_Title'] = Repository_title[0:33]\n",
    "Git['Repository_Desc']= Repository_desc[0:33]\n",
    "Git['Contributor_count'] = Contri_count[0:33]\n",
    "Git['Language'] = lang_note[0:33]\n",
    "Git.pd.Dataframe[0:33]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "51aefed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository_Title</th>\n",
       "      <th>Repository_Desc</th>\n",
       "      <th>Contributor_count</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[geohot / tinygrad, artidoro / qlora, ShishirP...</td>\n",
       "      <td>[You like pytorch? You like micrograd? You lov...</td>\n",
       "      <td>[Built by, Built by, Built by, Built by, Built...</td>\n",
       "      <td>[Python, Jupyter Notebook, Python, C++, PHP, J...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Repository_Title  \\\n",
       "0  [geohot / tinygrad, artidoro / qlora, ShishirP...   \n",
       "\n",
       "                                     Repository_Desc  \\\n",
       "0  [You like pytorch? You like micrograd? You lov...   \n",
       "\n",
       "                                   Contributor_count  \\\n",
       "0  [Built by, Built by, Built by, Built by, Built...   \n",
       "\n",
       "                                            Language  \n",
       "0  [Python, Jupyter Notebook, Python, C++, PHP, J...  "
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Git = pd.DataFrame({})\n",
    "Git['Repository_Title'] = pd.Series([Repository_title])\n",
    "Git['Repository_Desc']= pd.Series([Repository_desc])\n",
    "Git['Contributor_count'] = pd.Series([Contri_count])\n",
    "Git['Language'] = pd.Series([lang_note])\n",
    "Git\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1853cc",
   "metadata": {},
   "source": [
    "5. Scrape the details of top 100 songs on billiboard.com. \n",
    "Url = https:/www.billboard.com/\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edffae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the web driver\n",
    "web_driver = webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "#Get url in web driver first\n",
    "url = 'https://www.billboard.com/'\n",
    "web_driver.get(url)\n",
    "#the url will open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed86811a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#serch button click\n",
    "charts_button = web_driver.find_element(By.XPATH,\"//div[@class='search-form']\")\n",
    "charts_button.click()\n",
    "\n",
    "\n",
    "#/html/body/div[5]/div[9]/div/div/div/ul/li[1]/h3/button/span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db9d7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#serch button click\n",
    "top100_button = web_driver.find_element(By.XPATH,\"/html/body/div[4]/div[9]/div/div/div/ul/li[1]/ul/li[2]\")\n",
    "top100_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbb4214",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having song name\n",
    "name = web_driver.find_element(By.XPATH,\"//span[@class='chart-element__information__song text--truncate color--primary']\")\n",
    "#to remove extra data other than output we required\n",
    "Song_name = []\n",
    "for i in name:\n",
    "    Song_name.append(i.text)\n",
    "\n",
    "#extract the tag having artist name\n",
    "Artist = web_driver.find_element(By.XPATH,\"//span[@class='chart-element__information__artist text--truncate color--secondary']\")\n",
    "#to remove extra data other than output we required\n",
    "Artist_name = []\n",
    "for i in Artist:\n",
    "    Artist_name.append(i.text)\n",
    "\n",
    "#extract the tag having last week rank\n",
    "last_rank = web_driver.find_element(By.XPATH,\"//div[@class='chart-element__meta text--center color--secondary text--last']\")\n",
    "#to remove extra data other than output we required\n",
    "Last_week_rank = []\n",
    "for i in last_rank:\n",
    "    Last_week_rank.append(i.text)\n",
    "\n",
    "#extract the tag having last peak rank\n",
    "peak_rank = web_driver.find_element(By.XPATH,\"//div[@class='chart-element__meta text--center color--secondary text--peak']\")\n",
    "Peak_rank = []\n",
    "for i in peak_rank:\n",
    "    Peak_rank.append(i.text)\n",
    "\n",
    "#extract the tag having last week rank\n",
    "woc = web_driver.find_element(By.XPATH,\"//div[@class='chart-element__meta text--center color--secondary text--week']\")\n",
    "Weeks_on_chart = []\n",
    "for i in woc:\n",
    "    Weeks_on_chart.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae0dbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make data frame of hot 100 from https://www.billboard.com/\n",
    "HTop_list_100 = pd.DataFrame({})\n",
    "HTop_list_100['Song_name']= Song_name\n",
    "HTop_list_100['Artist_name'] = Artist_name\n",
    "HTop_list_100['Last_week_rank'] = Last_week_rank \n",
    "HTop_list_100['Peak_rank'] = Peak_rank\n",
    "HTop_list_100['Weeks_on_Board'] = Weeks_on_chart \n",
    "HTop_list_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b77d7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5a604a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5cf49b7f",
   "metadata": {},
   "source": [
    "6. Scrape the details of Highest sellingnovels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey\u0002compare\n",
    "You have to find the following details:\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "478dac9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the web driver\n",
    "web_driver = webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "#Get url in web driver first\n",
    "url = 'https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/'\n",
    "web_driver.get(url)\n",
    "#the url will open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "6686ac96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having rank\n",
    "rank = web_driver.find_elements(By.XPATH,\"//td[@class='left']\")\n",
    "#to remove extra data other than output we required\n",
    "\n",
    "Book_Name = []\n",
    "for i in rank:\n",
    "    Book_Name.append(i.text)\n",
    "BOOK_NAME = []\n",
    "for i in Book_Name[1: :5]:\n",
    "    BOOK_NAME.append(i)\n",
    "\n",
    "Auther_Name = []\n",
    "for i in Rank[2: :5]:\n",
    "    Auther_Name.append(i)\n",
    "\n",
    "Volume_sold = []\n",
    "for i in Rank[3: :5]:\n",
    "    Volume_sold.append(i)\n",
    "\n",
    "Publisher = []\n",
    "for i in Rank[4: :5]:\n",
    "    Publisher.append(i)\n",
    "\n",
    "#extract the tag having rank\n",
    "genre = web_driver.find_elements(By.XPATH,\"//td[@class='last left']\")\n",
    "#to remove extra data other than output we required\n",
    "Genre = []\n",
    "for i in genre:\n",
    "    Genre.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0353c711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make data frame of hot 100 from https://www.billboard.com/\n",
    "Novels = pd.DataFrame({})\n",
    "Novels['BOOK_NAME']= BOOK_NAME\n",
    "Novels['Auther_Name'] = Auther_Name\n",
    "Novels['Volume_sold'] = Volume_sold \n",
    "Novels['Publisher'] = Publisher\n",
    "Novels['Genre'] = Genre \n",
    "Novels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23273031",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "382c805b",
   "metadata": {},
   "source": [
    "7. Scrape the details most watched tv series of all time from imdb.com. \n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39199e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the web driver\n",
    "web_driver = webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "#Get url in web driver first\n",
    "url = 'https://www.imdb.com/list/ls095964455/'\n",
    "web_driver.get(url)\n",
    "#the url will open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "622cfe74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having Name\n",
    "name = web_driver.find_elements(By.XPATH,\"//h3[@class='lister-item-header']//a\")\n",
    "#to remove extra data other than output we required\n",
    "Name=[]\n",
    "for i in name:\n",
    "    Name.append(i.text)\n",
    "\n",
    "#extract the tag having year span\n",
    "year = web_driver.find_elements(By.XPATH,\"//span[@class='lister-item-year text-muted unbold']\")\n",
    "#to remove extra data other than output we required\n",
    "Year_Span=[]\n",
    "for i in year:\n",
    "    Year_Span.append(i.text)\n",
    "\n",
    "#extract the tag having Genre\n",
    "genre = web_driver.find_elements(By.XPATH,\"//span[@class='genre']\")\n",
    "#to remove extra data other than output we required\n",
    "Genre=[]\n",
    "for i in genre:\n",
    "    Genre.append(i.text)\n",
    "\n",
    "#extract the tag having run time\n",
    "run = web_driver.find_elements(By.XPATH,\"//span[@class='runtime']\")\n",
    "#to remove extra data other than output we required\n",
    "Run_Time=[]\n",
    "for i in run:\n",
    "    Run_Time.append(i.text)\n",
    "\n",
    "#extract the tag having ratings\n",
    "ratings = web_driver.find_elements(By.XPATH,\"//div[@class='ipl-rating-star small']\")\n",
    "#to remove extra data other than output we required\n",
    "Ratings=[]\n",
    "for i in ratings:\n",
    "    Ratings.append(i.text)\n",
    "\n",
    "#extract the tag having voting\n",
    "voting = web_driver.find_elements(By.XPATH,\"//span[@name='nv']\")\n",
    "\n",
    "#to remove extra data other than output we required\n",
    "Voting=[]\n",
    "for i in voting:\n",
    "    Voting.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "e3c6f3e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Voting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [NAME, Year Span, Genre, Run Time, Ratings, Voting]\n",
       "Index: []"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make data frame of tv series 100 from imdb.com\n",
    "TELEVISION_S = pd.DataFrame({})\n",
    "TELEVISION_S['NAME']= Name\n",
    "TELEVISION_S['Year Span'] = Year_Span\n",
    "TELEVISION_S['Genre'] = Genre \n",
    "TELEVISION_S['Run Time'] = Run_Time\n",
    "TELEVISION_S['Ratings'] = Ratings \n",
    "TELEVISION_S['Voting'] = Voting \n",
    "TELEVISION_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9116f45e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c93a73b",
   "metadata": {},
   "source": [
    "8. Details of Datasetsfrom UCI machine learning repositories. \n",
    "Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute\n",
    "G) Year\n",
    "Note: - from the home page you have to go to the ShowAllDataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59009015",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the web driver\n",
    "web_driver = webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "#Get url in web driver first\n",
    "url = 'https://archive.ics.uci.edu/'\n",
    "web_driver.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d78110",
   "metadata": {},
   "outputs": [],
   "source": [
    "#serch button click\n",
    "dataset_button = web_driver.find_element(By.XPATH,\"/html/body/table[1]/tbody/tr/td[2]/span[2]/a\")\n",
    "dataset_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13ef40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having dataset Name\n",
    "name = web_driver.find_elements(By.XPATH,\"//td[@valign='top']//a\")\n",
    "\n",
    "\n",
    "#to remove extra data other than output we required\n",
    "\n",
    "Dataset_Name=[]\n",
    "for i in name:\n",
    "    Dataset_Name.append(i.text)\n",
    "Dataset_name = []\n",
    "for i in Dataset_Name[44: :2]:\n",
    "    Dataset_name.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f262bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having dataset Name\n",
    "datat = web_driver.find_elements(By.XPATH,\"//td[@valign='top']//p\")\n",
    "#to remove extra data other than output we required\n",
    "Data_type=[]\n",
    "for i in datat:\n",
    "    Data_type.append(i.text)\n",
    "\n",
    "Data_Type=[]\n",
    "for i in Data_type[25: :7]:\n",
    "    Data_Type.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31334a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the tag having dataset Name\n",
    "task = web_driver.find_elements(By.XPATH,\"//td[@valign='top']//p\")\n",
    "#to remove extra data other than output we required\n",
    "Task=[]\n",
    "for i in task:\n",
    "    Task.append(i.text)\n",
    "\n",
    "TASK=[]\n",
    "for i in Task[26: :7]:\n",
    "    TASK.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f28236",
   "metadata": {},
   "outputs": [],
   "source": [
    "Attribute_Type=[]\n",
    "for i in Data_type[27: :7]:\n",
    "    Attribute_Type.append(i)\n",
    "Instances = []\n",
    "for i in Data_type[28: :7]:\n",
    "    Instances.append(i)\n",
    "Attribute=[]\n",
    "for i in Data_type[29: :7]:\n",
    "    Attribute.append(i)\n",
    "Year=[]\n",
    "for i in Data_type[30: :7]:\n",
    "    Year.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "e002cd50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset_name</th>\n",
       "      <th>Data_Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute_Type</th>\n",
       "      <th>Instances</th>\n",
       "      <th>Attribute</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td></td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>Influenza outbreak event prediction via Twitte...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>75840</td>\n",
       "      <td>525</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Turkish Music Emotion Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>400</td>\n",
       "      <td>50</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Maternal Health Risk Data Set</td>\n",
       "      <td></td>\n",
       "      <td>Classification</td>\n",
       "      <td></td>\n",
       "      <td>1014</td>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Room Occupancy Estimation</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>10129</td>\n",
       "      <td>16</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Image Recognition Task Execution Times in Mobi...</td>\n",
       "      <td>Univariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4000</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>622 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Dataset_name  \\\n",
       "0                                              Abalone   \n",
       "1                                                Adult   \n",
       "2                                            Annealing   \n",
       "3                         Anonymous Microsoft Web Data   \n",
       "4                                           Arrhythmia   \n",
       "..                                                 ...   \n",
       "617  Influenza outbreak event prediction via Twitte...   \n",
       "618                      Turkish Music Emotion Dataset   \n",
       "619                      Maternal Health Risk Data Set   \n",
       "620                          Room Occupancy Estimation   \n",
       "621  Image Recognition Task Execution Times in Mobi...   \n",
       "\n",
       "                      Data_Type                  Task  \\\n",
       "0                 Multivariate        Classification    \n",
       "1                 Multivariate        Classification    \n",
       "2                 Multivariate        Classification    \n",
       "3                                Recommender-Systems    \n",
       "4                 Multivariate        Classification    \n",
       "..                          ...                   ...   \n",
       "617               Multivariate        Classification    \n",
       "618               Multivariate        Classification    \n",
       "619                                   Classification    \n",
       "620  Multivariate, Time-Series        Classification    \n",
       "621                 Univariate            Regression    \n",
       "\n",
       "                  Attribute_Type Instances Attribute   Year  \n",
       "0    Categorical, Integer, Real      4177         8   1995   \n",
       "1          Categorical, Integer     48842        14   1996   \n",
       "2    Categorical, Integer, Real       798        38          \n",
       "3                   Categorical     37711       294   1998   \n",
       "4    Categorical, Integer, Real       452       279   1998   \n",
       "..                           ...       ...       ...    ...  \n",
       "617               Integer, Real     75840       525   2020   \n",
       "618               Integer, Real       400        50   2020   \n",
       "619                                  1014         7   2020   \n",
       "620                        Real     10129        16   2021   \n",
       "621                        Real      4000         2   2021   \n",
       "\n",
       "[622 rows x 7 columns]"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make data frame of Datasets from UCI machine learning repositories from Url = https://archive.ics.uci.edu/\n",
    "\n",
    "MACHINE_LEARNING_REPO = pd.DataFrame({})\n",
    "MACHINE_LEARNING_REPO['Dataset_name']= Dataset_name\n",
    "MACHINE_LEARNING_REPO['Data_Type'] = Data_Type\n",
    "MACHINE_LEARNING_REPO['Task'] = TASK \n",
    "MACHINE_LEARNING_REPO['Attribute_Type'] = Attribute_Type\n",
    "MACHINE_LEARNING_REPO['Instances'] = Instances \n",
    "MACHINE_LEARNING_REPO['Attribute'] = Attribute \n",
    "MACHINE_LEARNING_REPO['Year'] = Year\n",
    "MACHINE_LEARNING_REPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6fb29a",
   "metadata": {},
   "source": [
    "9. Scrape the details of Data science recruiters Url = https://www.naukri.com/hr-recruiters-consultants\n",
    "You have to find the following details: \n",
    "A) Name\n",
    "B) Designation\n",
    "C)Company \n",
    "D)Skills they hire for \n",
    "E) Location\n",
    "Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and \n",
    "click on search. All this should be done through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "c71dd527",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to the web driver\n",
    "web_driver = webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "#Get url in web driver first\n",
    "url = ' https://www.naukri.com/hr-recruiters-consultants'\n",
    "web_driver.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "4c596204",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#inspect for Skill,Designations,Companies field\n",
    "ds_search = web_driver.find_element(By.XPATH,\"//input[@class='sugInp']\")\n",
    "\n",
    "#this will write text on search bar\n",
    "ds_search.send_keys('Data science')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "084a9aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#serch button click\n",
    "search_button = web_driver.find_element(By.XPATH,\"//button[@class='fl qsbSrch blueBtn']\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a35bfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c18e5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df16dda0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee082c00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
